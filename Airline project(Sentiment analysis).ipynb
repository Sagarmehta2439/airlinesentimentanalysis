{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In Class Project\n",
    "The dataset has been taken from Kaggle.\n",
    "(https://www.kaggle.com/crowdflower/twitter-airline-sentiment/home)\n",
    "This is a dataset having tweets about 6 US Airlines along with their sentiments:\n",
    "positive, negative and neutral.\n",
    "You are provided with two files: ‘Tweets-train.csv” and ‘Tweets-test.csv”\n",
    "The train data contains about 11000 tweets and test contains 4000 tweets. You have\n",
    "to perform Sentiment Analysis on the dataset and also built a classifier on the\n",
    "training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Read the training using pandas module and select only the sentiment and text\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300616901320704</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:13:57 -0800</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570301130888122368          positive                        0.3486   \n",
       "1  570301083672813571           neutral                        0.6837   \n",
       "2  570301031407624196          negative                        1.0000   \n",
       "3  570300817074462722          negative                        1.0000   \n",
       "4  570300616901320704          positive                        0.6745   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                     0.0000  Virgin America   \n",
       "1            NaN                        NaN  Virgin America   \n",
       "2     Bad Flight                     0.7033  Virgin America   \n",
       "3     Can't Tell                     1.0000  Virgin America   \n",
       "4            NaN                     0.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN    jnardino                 NaN              0   \n",
       "1                    NaN  yvonnalynn                 NaN              0   \n",
       "2                    NaN    jnardino                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN  cjmcginnis                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "1  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "2  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "3  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "\n",
       "               tweet_created    tweet_location               user_timezone  \n",
       "0  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)  \n",
       "1  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)  \n",
       "2  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)  \n",
       "3  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train = pd.read_csv('Tweets-train.csv')\n",
    "tweet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweet_train[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0          positive  @VirginAmerica plus you've added commercials t...\n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "2          negative  @VirginAmerica it's really aggressive to blast...\n",
       "3          negative  @VirginAmerica and it's a really big bad thing...\n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "• Observe randomly generated 10 tweets for each sentiment with respect to the\n",
    "following:\n",
    "o Text contains references with ‘@’\n",
    "o Text contains links (http , https )\n",
    "o Text contains punctuations\n",
    "o Text contains Emoticons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentiments(sentiment):\n",
    "    for tweet in tweets[tweets['airline_sentiment'] == sentiment].sample(10,random_state = 89)['text']:\n",
    "        x = print(tweet)\n",
    "    return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue after applying my new tag, she left my bag on the ground rather than loading on the conveyer belt..I had to walk back 50 yards\n",
      "@united apparently sleeping in B terminal wasn't the worst situation. Someone told other UA passengers they had to sleep at baggage claim.\n",
      "@united I would understand if weather was the issue, but bc of airline maintenance I had to sleep on an airport floor and lose an entire day\n",
      "@AmericanAir no you're not you're trying to book me PAST when i need 2 arrive but you're still selling seats on the day I'm trying 2 travel\n",
      "@united  why is it so hard to add in meal preferences AFTER I booked tickets? I forgot to do it &amp; it's now impossible! I even called.\n",
      "@united \"where we trick you into making us look popular on Twitter by being the worst airline\" #wellplayed #jokesonus\n",
      "@united not the case. Now delayed due to \"mechanical issues with no update on departure time\". Just Cancelled Flight the goddamn flight so I go delta\n",
      "Thanks @united for writing back. To assist you can return the bag you lost &amp; clean up the feces sprinkled in your bathroom. Too much to ask?\n",
      "@USAirways delays due to refueling are out of your control? If that's true I never want to fly US Airways again\n",
      "@JetBlue - Fix your @#$&amp; jet bridges.  40 minute delay, 2nd gate...still waiting!  #jetblues http://t.co/ncB2oNcS9i\n"
     ]
    }
   ],
   "source": [
    "check_sentiments(\"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue Airways Reveals 'Bluemanity' Livery - TravelPulse http://t.co/fTTfyFMvCO\n",
      "@USAirways YOU ARE THE BEST!!! FOLLOW ME PLEASE;)🙏🙏🙏✌️✌️✌️🙏🙏🙏\n",
      "@united yes #LHRT2 lounge is fantastic, if only the US ones could be remotely similar!\n",
      "@united good job at CLE .. TPA on schedule ... 4 to 5 inches of snow ! http://t.co/9tbsJquw41\n",
      "@JetBlue, was far less painful than what was coming from Avis.  💙\n",
      "@jetblue #philly lost and read program - Our customers get hot tea, great crewmembers, top notch info &amp; now #BOOKS! http://t.co/9rAGncw2Bk\n",
      "@united enjoyed #heathrow lounge so much i almost missed my @airnzusa flight!\n",
      "@united Both flights went great and improved my view of your airline, cheers! Flight attendents on UA1022 deserve a raise\n",
      "@JetBlue why yes, yes it does!!!!  Great trip down!! Thanks for the lift!!!!\n",
      "@AmericanAir Haha I had a boarding pass for 12B, was boarding the plane and the gate agent told me to go to 41G. I'm here now. No worries.\n"
     ]
    }
   ],
   "source": [
    "check_sentiments(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SouthwestAir I was not the one traveling. I was asking for my sister who was waiting on my nephew in Midland...flight eventually landed\n",
      "@united can you get me to okc from Sacramento today. Dfw is now closed\n",
      "@SouthwestAir how about some sweet promo code to help me visit my family!!!.... Please!!!... Lol\n",
      "@united hi -- @united was. Thank you!\n",
      "@SouthwestAir Just sent you a DM with the details.\n",
      "@JetBlue Fliers to Gain Access to WSJ Content - @zacks_com http://t.co/GouzrdT7ZF\n",
      "@united I got it now. Wouldn't let me log on with my email. Thx. Here's hoping for dtw-ase without issue today\n",
      "@SouthwestAir will do! #heart #flying\n",
      "@SouthwestAir i hope i can take my selfie stick on the plane today! #goingtovegas\n",
      "@SouthwestAir if only you could control the weather in Las Vegas 😉\n"
     ]
    }
   ],
   "source": [
    "check_sentiments(\"neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to prepare a function to clean all the above observed tokens from the tweet text.\n",
    "Save changes in a new column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(text):\n",
    "    from nltk.tokenize import WordPunctTokenizer\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    import re\n",
    "    text=re.sub(r'@+','',text)\n",
    "    text=re.sub('http?://[A-Za-z0-9./]+','',text)\n",
    "    text=re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    lower_case = text.lower()\n",
    "    words = tokenizer.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "\n",
       "                                        text_cleaned  \n",
       "0  virginamerica plus you ve added commercials to...  \n",
       "1  virginamerica i didn t today must mean i need ...  \n",
       "2  virginamerica it s really aggressive to blast ...  \n",
       "3  virginamerica and it s a really big bad thing ...  \n",
       "4  virginamerica yes nearly every time i fly vx t...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text_cleaned'] = tweets['text'].apply(tweet_cleaner)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('to', 4326), ('i', 3313), ('the', 3021), ('a', 2344), ('flight', 2113), ('united', 2101), ('and', 2049), ('on', 2023), ('for', 1999), ('you', 1959), ('my', 1726), ('usairways', 1722), ('americanair', 1549), ('is', 1526), ('t', 1327)]\n",
      "neutral\n",
      "[('to', 1185), ('i', 1004), ('the', 730), ('a', 616), ('you', 561), ('jetblue', 540), ('united', 530), ('southwestair', 489), ('on', 479), ('for', 443), ('flight', 436), ('my', 391), ('is', 372), ('americanair', 363), ('in', 355)]\n",
      "positive\n",
      "[('the', 690), ('to', 675), ('you', 672), ('i', 555), ('for', 493), ('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('a', 385), ('united', 376), ('thank', 336), ('and', 306), ('flight', 269), ('my', 263), ('americanair', 254)]\n"
     ]
    }
   ],
   "source": [
    "#See some words in All sentiments\n",
    "\n",
    "from collections import Counter\n",
    "for group_name,subset in tweets.groupby('airline_sentiment'):\n",
    "    sentimentData=subset['text_cleaned']\n",
    "    words=[]\n",
    "    for each in sentimentData:\n",
    "        words.extend(each.split(\" \"))\n",
    "    print(group_name)\n",
    "    print(Counter(words).most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords from all the tweets.\n",
    "Save changes in a new column and list down most common 15 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean-text_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "4  virginamerica yes nearly every time i fly vx t...   \n",
       "\n",
       "                                  clean-text_removed  \n",
       "0  virginamerica plus added commercial experience...  \n",
       "1  virginamerica today must mean need take anothe...  \n",
       "2  virginamerica really aggressive blast obnoxiou...  \n",
       "3                 virginamerica really big bad thing  \n",
       "4  virginamerica yes nearly every time fly vx ear...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import  wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Tokenize Function\n",
    "def Tokenize(string):\n",
    "    tokens=nltk.tokenize.word_tokenize(string)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "#RemoveStopWordsFunction\n",
    "def RemoveStopWords(string):\n",
    "    #Removing Punctuations\n",
    "    for each in punctuation:\n",
    "        string=string.replace(each,\"\")\n",
    "    \n",
    "    #Removing Stopwords\n",
    "    english_stopwords=stopwords.words('english')\n",
    "    stopwords_removed_tokens=[]\n",
    "    words=string.split(\" \")\n",
    "    \n",
    "    for each in words:\n",
    "        if each not in english_stopwords:\n",
    "            stopwords_removed_tokens.append(each)\n",
    "    return \" \".join(stopwords_removed_tokens) \n",
    "\n",
    "\n",
    "#LemmatizeFunction\n",
    "def Lemmatize(string):\n",
    "    word_lem=WordNetLemmatizer()\n",
    "    words=string.split() \n",
    "    lemmatizeWords=[]\n",
    "    for each in words:\n",
    "        lemmatizeWords.append(word_lem.lemmatize(each))\n",
    "    return \" \".join(lemmatizeWords)\n",
    "\n",
    "def Refine(string):\n",
    "    return Lemmatize(RemoveStopWords(Tokenize(string)))\n",
    "\n",
    "\n",
    "tweets['clean-text_removed'] = tweets['text_cleaned'].apply(Refine)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('flight', 2419), ('united', 2101), ('usairways', 1722), ('americanair', 1549), ('southwestair', 884), ('hour', 826), ('jetblue', 755), ('get', 751), ('cancelled', 648), ('u', 554), ('customer', 545), ('service', 541), ('time', 539), ('bag', 477), ('help', 446)]\n",
      "neutral\n",
      "[('flight', 566), ('jetblue', 540), ('united', 530), ('southwestair', 489), ('americanair', 363), ('usairways', 302), ('get', 175), ('please', 132), ('virginamerica', 130), ('need', 127), ('help', 121), ('thanks', 115), ('u', 97), ('would', 92), ('dm', 92)]\n",
      "positive\n",
      "[('thanks', 448), ('jetblue', 443), ('southwestair', 424), ('united', 376), ('thank', 336), ('flight', 308), ('americanair', 254), ('usairways', 199), ('great', 165), ('service', 122), ('virginamerica', 114), ('love', 106), ('u', 100), ('customer', 91), ('guy', 91)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for group_name,subset in tweets.groupby('airline_sentiment'):\n",
    "    sentiment_data = subset['clean-text_removed']\n",
    "    words = []\n",
    "    for word in sentiment_data:\n",
    "        words.extend(word.split(\" \"))\n",
    "    print(group_name)\n",
    "    print(Counter(words).most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Remove these words from all the tweets.\n",
    "americanair, united, delta, southwestair, jetblue, virginamerica, usairways,\n",
    "flight, plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveExplicitlyMentionedWords(string,listofWordsToRemove):\n",
    "    listOfAllWords=string.split(\" \")\n",
    "    listOfWords= [x for x in listOfAllWords if x not in listofWordsToRemove]\n",
    "    return (\" \".join(listOfWords)).strip()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean-text_removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "      <td>plus added commercial experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "4  virginamerica yes nearly every time i fly vx t...   \n",
       "\n",
       "                                  clean-text_removed  \\\n",
       "0  virginamerica plus added commercial experience...   \n",
       "1  virginamerica today must mean need take anothe...   \n",
       "2  virginamerica really aggressive blast obnoxiou...   \n",
       "3                 virginamerica really big bad thing   \n",
       "4  virginamerica yes nearly every time fly vx ear...   \n",
       "\n",
       "                                 Final-Wrangled-Text  \n",
       "0             plus added commercial experience tacky  \n",
       "1             today must mean need take another trip  \n",
       "2  really aggressive blast obnoxious entertainmen...  \n",
       "3                               really big bad thing  \n",
       "4      yes nearly every time fly vx ear worm go away  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words_to_remove=['americanair','united','delta','southwestair','jetblue','virginamerica','usairways','flight','plane']\n",
    "tweets['Final-Wrangled-Text']=list(map(lambda x:RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),tweets['clean-text_removed']))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n",
      "[('hour', 826), ('get', 751), ('cancelled', 648), ('u', 554), ('customer', 545), ('service', 541), ('time', 539), ('bag', 477), ('help', 446), ('hold', 426), ('delayed', 371), ('amp', 368), ('call', 368), ('still', 363), ('day', 331)]\n",
      "neutral\n",
      "[('get', 175), ('please', 132), ('need', 127), ('help', 121), ('thanks', 115), ('u', 97), ('would', 92), ('dm', 92), ('time', 87), ('ticket', 83), ('tomorrow', 76), ('cancelled', 74), ('amp', 73), ('know', 72), ('fleek', 70)]\n",
      "positive\n",
      "[('thanks', 448), ('thank', 336), ('great', 165), ('service', 122), ('love', 106), ('u', 100), ('customer', 91), ('guy', 91), ('best', 85), ('good', 83), ('get', 80), ('airline', 78), ('much', 77), ('time', 73), ('got', 72)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for group_name,subset in tweets.groupby('airline_sentiment'):\n",
    "    sentiment_data = subset['Final-Wrangled-Text']\n",
    "    words = []\n",
    "    for word in sentiment_data:\n",
    "        words.extend(word.split(\" \"))\n",
    "    print(group_name)\n",
    "    print(Counter(words).most_common(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Encode Sentiments using Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean-text_removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus you ve added commercials to...</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "      <td>plus added commercial experience tacky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica i didn t today must mean i need ...</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "      <td>today must mean need take another trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica it s really aggressive to blast ...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica and it s a really big bad thing ...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>virginamerica yes nearly every time i fly vx t...</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          positive  @VirginAmerica plus you've added commercials t...   \n",
       "1           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "2          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "3          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "4          positive  @VirginAmerica yes, nearly every time I fly VX...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  virginamerica plus you ve added commercials to...   \n",
       "1  virginamerica i didn t today must mean i need ...   \n",
       "2  virginamerica it s really aggressive to blast ...   \n",
       "3  virginamerica and it s a really big bad thing ...   \n",
       "4  virginamerica yes nearly every time i fly vx t...   \n",
       "\n",
       "                                  clean-text_removed  \\\n",
       "0  virginamerica plus added commercial experience...   \n",
       "1  virginamerica today must mean need take anothe...   \n",
       "2  virginamerica really aggressive blast obnoxiou...   \n",
       "3                 virginamerica really big bad thing   \n",
       "4  virginamerica yes nearly every time fly vx ear...   \n",
       "\n",
       "                                 Final-Wrangled-Text  sentiment_label  \n",
       "0             plus added commercial experience tacky                2  \n",
       "1             today must mean need take another trip                1  \n",
       "2  really aggressive blast obnoxious entertainmen...                0  \n",
       "3                               really big bad thing                0  \n",
       "4      yes nearly every time fly vx ear worm go away                2  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment_label'] = le.fit_transform(tweets['airline_sentiment'])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6670\n",
       "1    2248\n",
       "2    1722\n",
       "Name: sentiment_label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the Text Column (You can choose any vectorizer of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x9347 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 36 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = vectorizer.fit_transform(tweets['Final-Wrangled-Text'])\n",
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Prepare a multiclass Classification model using any classification algorithm\n",
    "and create a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tweets['sentiment_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the test data and carry our data cleaning, encoding and vectorising\n",
    "operations on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir why did you drop my call. Why don...</td>\n",
       "      <td>americanair why did you drop my call why don t...</td>\n",
       "      <td>americanair drop call people answering phone a...</td>\n",
       "      <td>drop call people answering phone always high c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways thanks for the seat that doesn't re...</td>\n",
       "      <td>usairways thanks for the seat that doesn t rec...</td>\n",
       "      <td>usairways thanks seat recline shocked asked se...</td>\n",
       "      <td>thanks seat recline shocked asked serve everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir wasn't just a delay. Your counter...</td>\n",
       "      <td>americanair wasn t just a delay your counter w...</td>\n",
       "      <td>americanair delay counter take valid cac card ...</td>\n",
       "      <td>delay counter take valid cac card valid id nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united social media team is on point on #Osca...</td>\n",
       "      <td>united social media team is on point on oscarn...</td>\n",
       "      <td>united social medium team point oscarnight</td>\n",
       "      <td>social medium team point oscarnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir These birds could fly to South Am...</td>\n",
       "      <td>americanair these birds could fly to south ame...</td>\n",
       "      <td>americanair bird could fly south america examp...</td>\n",
       "      <td>bird could fly south america example argentina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          negative  @AmericanAir why did you drop my call. Why don...   \n",
       "1          negative  @USAirways thanks for the seat that doesn't re...   \n",
       "2          negative  @AmericanAir wasn't just a delay. Your counter...   \n",
       "3          positive  @united social media team is on point on #Osca...   \n",
       "4           neutral  @AmericanAir These birds could fly to South Am...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  americanair why did you drop my call why don t...   \n",
       "1  usairways thanks for the seat that doesn t rec...   \n",
       "2  americanair wasn t just a delay your counter w...   \n",
       "3  united social media team is on point on oscarn...   \n",
       "4  americanair these birds could fly to south ame...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \\\n",
       "0  americanair drop call people answering phone a...   \n",
       "1  usairways thanks seat recline shocked asked se...   \n",
       "2  americanair delay counter take valid cac card ...   \n",
       "3         united social medium team point oscarnight   \n",
       "4  americanair bird could fly south america examp...   \n",
       "\n",
       "                                 Final-Wrangled-Text  \n",
       "0  drop call people answering phone always high c...  \n",
       "1  thanks seat recline shocked asked serve everyo...  \n",
       "2  delay counter take valid cac card valid id nee...  \n",
       "3                social medium team point oscarnight  \n",
       "4     bird could fly south america example argentina  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('Tweets-test.csv')\n",
    "list_of_words_to_remove=['americanair','united','delta','southwestair','jetblue','virginamerica','usairways','flight','plane']\n",
    "#test.head()\n",
    "test_new = test.loc[:,['airline_sentiment','text']]\n",
    "test_new['text_cleaned'] = list(map(lambda x: tweet_cleaner(x),test_new['text']))\n",
    "test_new['Clean-Text-StopWords-Removed'] = list(map(lambda x: Refine(x),test_new['text_cleaned']))\n",
    "test_new['Final-Wrangled-Text'] = list(map(lambda x: RemoveExplicitlyMentionedWords(x,list_of_words_to_remove),test_new['Clean-Text-StopWords-Removed']))\n",
    "test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>Clean-Text-StopWords-Removed</th>\n",
       "      <th>Final-Wrangled-Text</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir why did you drop my call. Why don...</td>\n",
       "      <td>americanair why did you drop my call why don t...</td>\n",
       "      <td>americanair drop call people answering phone a...</td>\n",
       "      <td>drop call people answering phone always high c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@USAirways thanks for the seat that doesn't re...</td>\n",
       "      <td>usairways thanks for the seat that doesn t rec...</td>\n",
       "      <td>usairways thanks seat recline shocked asked se...</td>\n",
       "      <td>thanks seat recline shocked asked serve everyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir wasn't just a delay. Your counter...</td>\n",
       "      <td>americanair wasn t just a delay your counter w...</td>\n",
       "      <td>americanair delay counter take valid cac card ...</td>\n",
       "      <td>delay counter take valid cac card valid id nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united social media team is on point on #Osca...</td>\n",
       "      <td>united social media team is on point on oscarn...</td>\n",
       "      <td>united social medium team point oscarnight</td>\n",
       "      <td>social medium team point oscarnight</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir These birds could fly to South Am...</td>\n",
       "      <td>americanair these birds could fly to south ame...</td>\n",
       "      <td>americanair bird could fly south america examp...</td>\n",
       "      <td>bird could fly south america example argentina</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0          negative  @AmericanAir why did you drop my call. Why don...   \n",
       "1          negative  @USAirways thanks for the seat that doesn't re...   \n",
       "2          negative  @AmericanAir wasn't just a delay. Your counter...   \n",
       "3          positive  @united social media team is on point on #Osca...   \n",
       "4           neutral  @AmericanAir These birds could fly to South Am...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  americanair why did you drop my call why don t...   \n",
       "1  usairways thanks for the seat that doesn t rec...   \n",
       "2  americanair wasn t just a delay your counter w...   \n",
       "3  united social media team is on point on oscarn...   \n",
       "4  americanair these birds could fly to south ame...   \n",
       "\n",
       "                        Clean-Text-StopWords-Removed  \\\n",
       "0  americanair drop call people answering phone a...   \n",
       "1  usairways thanks seat recline shocked asked se...   \n",
       "2  americanair delay counter take valid cac card ...   \n",
       "3         united social medium team point oscarnight   \n",
       "4  americanair bird could fly south america examp...   \n",
       "\n",
       "                                 Final-Wrangled-Text  sentiment_label  \n",
       "0  drop call people answering phone always high c...                0  \n",
       "1  thanks seat recline shocked asked serve everyo...                0  \n",
       "2  delay counter take valid cac card valid id nee...                0  \n",
       "3                social medium team point oscarnight                2  \n",
       "4     bird could fly south america example argentina                1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new['sentiment_label'] = le.fit_transform(test_new['airline_sentiment'])\n",
    "test_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Vectorize the Text Column (You can choose any vectorizer of your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=vectorizer.transform(test_new['Final-Wrangled-Text'])\n",
    "#Encoding label for test data as well\n",
    "y_test=test_new['sentiment_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Prepare a multiclass Classification model using any classification algorithm\n",
    "and create a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding label for test data as well\n",
    "y_test=test_new['sentiment_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Predict the sentiments for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=nb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AmericanAir why did you drop my call. Why don...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USAirways thanks for the seat that doesn't re...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@AmericanAir wasn't just a delay. Your counter...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@united social media team is on point on #Osca...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AmericanAir These birds could fly to South Am...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0  @AmericanAir why did you drop my call. Why don...          negative   \n",
       "1  @USAirways thanks for the seat that doesn't re...          negative   \n",
       "2  @AmericanAir wasn't just a delay. Your counter...          negative   \n",
       "3  @united social media team is on point on #Osca...          positive   \n",
       "4  @AmericanAir These birds could fly to South Am...           neutral   \n",
       "\n",
       "  Predicted_sentiment  \n",
       "0            negative  \n",
       "1            negative  \n",
       "2            negative  \n",
       "3            negative  \n",
       "4             neutral  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetOrignalSentiment(val):\n",
    "    if val==0:\n",
    "        return 'negative'\n",
    "    elif val==1:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "Result=test_new.loc[:,['text','airline_sentiment']]\n",
    "Result['Predicted_sentiment']=list(map(lambda x:GetOrignalSentiment(x),y_pred))\n",
    "Result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      " [[2397   80   31]\n",
      " [ 452  335   64]\n",
      " [ 219   54  368]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\\n\",metrics.confusion_matrix(Result['airline_sentiment'],Result['Predicted_sentiment'],labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual negative Predicted negative: 2397\n",
      "Actual negative Predicted neutral: 80\n",
      "Actual negative Predicted positive: 31\n",
      "Actual neutral Predicted negative: 452\n",
      "Actual neutral Predicted neutral: 335\n",
      "Actual neutral Predicted positive: 64\n",
      "Actual positive Predicted negative: 219\n",
      "Actual positive Predicted neutral: 54\n",
      "Actual positive Predicted positive: 368\n"
     ]
    }
   ],
   "source": [
    "#Explaning Confusion Matrix Elements\n",
    "\n",
    "for i,x in Result.groupby(['airline_sentiment','Predicted_sentiment']):\n",
    "    print(\"Actual \"+ i[0]+ \" Predicted \"+i[1]+ \":\", len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 77.35 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy :\n",
    "ActualNegativePrdictedNegative=2396\n",
    "ActualNeutralPrdictedNeutral=333\n",
    "ActualPositivePrdictedPositive=365\n",
    "TotalCorrect=ActualNegativePrdictedNegative+ActualNeutralPrdictedNeutral+ActualPositivePrdictedPositive\n",
    "print(\"Accuracy=\",TotalCorrect*100.0/len(test) ,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
